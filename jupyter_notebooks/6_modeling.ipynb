{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling profitability (binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import itertools\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/ryanrappa/Desktop/dsi/film-profit-prediction/csv_files/clean_data_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping non-numerical and unnecessary cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to try modeling without competitor, because this probably makes things\n",
    "# easier for end users who want to predict their film's potential profitability;\n",
    "# it would probably be difficult for many end users to guess at competitor \n",
    "# metrics to input into the mode. Additionally,\n",
    "\n",
    "# I noticed in EDA that the relationship btw competition and profit looks \n",
    "# random/non-existent. Also, when running logistic regression, I observed\n",
    "# that including competitor metrics actually LOWERS accuracy\n",
    "# and does not meaningfully improve fallout\n",
    "\n",
    "cols_X = ['runtime', 'releases', 'cast_rev', 'cast_prof', 'cast_films', 'cast_prof_films', 'dir_rev',\n",
    "       'dir_prof', 'dir_films', 'dir_prof_films', 'writ_rev', 'writ_prof', 'writ_films',\n",
    "       'writ_prof_films', 'adj_budget', 'cast_dir_avg_rev', \n",
    "       'fall', 'spring', 'summer', 'winter', 'Action', 'Adventure', 'Animation',\n",
    "       'Comedy', 'Crime', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery',\n",
    "       'None', 'Romance', 'Science Fiction', 'Thriller', 'War', 'Western']\n",
    "\n",
    "### competitor metrics column names:\n",
    "# , 'compet_cast_rev', 'compet_cast_prof', 'compet_cast_films',\n",
    "#        'compet_cast_prof_films', 'compet_dir_rev', 'compet_dir_prof', 'compet_dir_films',\n",
    "#        'compet_dir_prof_films', 'compet_writ_rev', 'compet_writ_prof', 'compet_writ_films',\n",
    "#        'compet_writ_prof_films']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_y = ['made_money']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, cols_X].values\n",
    "y = df.loc[:, col_y].values.ravel() \n",
    "#need to use ravel for y array to be correct shape for analysis, \n",
    "#otherwise np.mean(y_pred == y_test) does not work properly later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled data for use with logsitic regression and SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to show confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### source: https://www.kaggle.com/dstuerzer/optimized-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "#    else:\n",
    "#        print('Confusion matrix, without normalization')\n",
    "\n",
    "#    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "def show_data(cm, print_res = 0):\n",
    "    tp = cm[1,1]\n",
    "    fn = cm[1,0]\n",
    "    fp = cm[0,1]\n",
    "    tn = cm[0,0]\n",
    "    if print_res == 1:\n",
    "        print('Accuracy =     {:.3f}'.format((tp+tn)/(tp+fp+tn+fn)))  #my addition\n",
    "        print('Precision =     {:.3f}'.format(tp/(tp+fp)))\n",
    "        print('Recall (TPR) =  {:.3f}'.format(tp/(tp+fn)))\n",
    "        print('Fallout (FPR) = {:.3f}'.format(fp/(fp+tn)))\n",
    "    return (tp+tn)/(tp+fp+tn+fn), tp/(tp+fp), tp/(tp+fn), fp/(fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data is imbalanced (has mostly profitable films), so using stratified train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state=313)\n",
    "for train_index, test_index in skf.split(X_scaled, y):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = LogisticRegression(penalty='l1')  #l1 penalty performs MUCH better than l2 penalty\n",
    "\n",
    "lrn.fit(X_train, y_train)\n",
    "y_pred = lrn.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "if lrn.classes_[0] == 1:\n",
    "    cm = np.array([[cm[1,1], cm[1,0]], [cm[0,1], cm[0,0]]])\n",
    "\n",
    "plot_confusion_matrix(cm, ['0', '1'], )\n",
    "acc, pr, tpr, fpr = show_data(cm, print_res = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy is the percentage of correct predictions (classifications) made by the model.\n",
    "#### Precision is the probability that a film that is classified as profitable actually made money.\n",
    "#### Recall (True Positive Rate) is the probability that a profitable film is classified as such.\n",
    "#### Fallout (False Positive Rate) is the probability that an unprofitable film is wrongly classified as profitable. **Really important to minimize fallout if we don't want to make unprofitable movies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_pred == y_test) #accuracy checks out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning - looking at ROC curves & confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to plot ROC. Source: https://www.kaggle.com/dstuerzer/optimized-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC(X, y, c, r):\n",
    "#makes cross_validation for given parameters c,r. Returns FPR, TPR (averaged)\n",
    "    dic_weight = {1:len(y)/(r*np.sum(y)), 0:len(y)/(len(y)-r*np.sum(y))} \n",
    "    #unfortunately this takes too long to run with l1 penalty, so looking at l2\n",
    "    lrn = LogisticRegression(penalty = 'l2', C = c, class_weight = dic_weight,\n",
    "                             solver='liblinear') #specifying default solver to avoid a zillion warnings printing\n",
    "    \n",
    "    N = 5      #how much k-fold\n",
    "    N_iter = 3    #repeat how often (taking the mean)\n",
    "    mean_tpr = 0.0\n",
    "    mean_thresh = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 50000)\n",
    "    \n",
    "\n",
    "    for it in range(N_iter):\n",
    "        skf = StratifiedKFold(n_splits = N, shuffle = True)\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, y_train = X[train_index], y[train_index]\n",
    "            X_test, y_test = X[test_index], y[test_index]\n",
    "         \n",
    "            lrn.fit(X_train, y_train)\n",
    "            y_prob = lrn.predict_proba(X_test)[:,lrn.classes_[1]]\n",
    "            \n",
    "            fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "            mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "            mean_thresh += np.interp(mean_fpr, fpr, thresholds)\n",
    "            mean_tpr[0] = 0.0\n",
    "\n",
    "    mean_tpr /= (N*N_iter)\n",
    "    mean_thresh /= (N*N_iter)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    return mean_fpr, mean_tpr, roc_auc_score(y_test, y_prob), mean_thresh\n",
    "\n",
    "def plot_roc(X,y, list_par_1, par_1 = 'C', par_2 = 1):\n",
    "\n",
    "    f = plt.figure(figsize = (9,6));\n",
    "    for p in list_par_1:\n",
    "        if par_1 == 'C':\n",
    "            c = p\n",
    "            r = par_2\n",
    "        else:\n",
    "            r = p\n",
    "            c = par_2\n",
    "        list_FP, list_TP, AUC, mean_thresh = ROC(X, y, c, r)      \n",
    "        plt.plot(list_FP, list_TP, label = 'C = {}, r = {}, TPR(3e-4) = {:.4f}, AUC = {:.4f}'.format(c,r,list_TP[10],AUC));\n",
    "    plt.legend(title = 'values', loc='lower right')\n",
    "    plt.xlim(0, 1)   #we are only interested in small values of FPR\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC detail')\n",
    "    desired_fpr = 0.2\n",
    "    plt.axvline(desired_fpr, color='b', linestyle='dashed', linewidth=2) #line to show where desired FPR occurs \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casual/visual grid search 1: Look for optimal class_weight, 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(X,y, [10, 1,.1,.01,.001], 'r', 1)\n",
    "# looks like r = 1 (default) is best\n",
    "# I think this makes sense because we did stratified train-test split earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casual/visual grid search 2: Look for optimal 'C' (inverse regularization strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(X,y, [0.001, 0.01, 0.1, 1, 10], 'C', 1)\n",
    "# differences are so small it hardly matters\n",
    "# running this repeatedly shows no pattern in terms of one C value standing out\n",
    "# so we'll stick with the default C = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casual/visual grid search 3: checking different decision boundaries - 60, 65, 70, 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (lrn.predict_proba(X_test)[:,1] >= 0.6).astype(bool)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "if lrn.classes_[0] == 1:\n",
    "    cm = np.array([[cm[1,1], cm[1,0]], [cm[0,1], cm[0,0]]])\n",
    "\n",
    "plot_confusion_matrix(cm, ['0', '1'], )\n",
    "acc, pr, tpr, fpr = show_data(cm, print_res = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (lrn.predict_proba(X_test)[:,1] >= 0.7).astype(bool)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "if lrn.classes_[0] == 1:\n",
    "    cm = np.array([[cm[1,1], cm[1,0]], [cm[0,1], cm[0,0]]])\n",
    "\n",
    "plot_confusion_matrix(cm, ['0', '1'], )\n",
    "acc, pr, tpr, fpr = show_data(cm, print_res = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (lrn.predict_proba(X_test)[:,1] >= 0.8).astype(bool)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "if lrn.classes_[0] == 1:\n",
    "    cm = np.array([[cm[1,1], cm[1,0]], [cm[0,1], cm[0,0]]])\n",
    "\n",
    "plot_confusion_matrix(cm, ['0', '1'], )\n",
    "acc, pr, tpr, fpr = show_data(cm, print_res = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (lrn.predict_proba(X_test)[:,1] >= 0.65).astype(bool)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "if lrn.classes_[0] == 1:\n",
    "    cm = np.array([[cm[1,1], cm[1,0]], [cm[0,1], cm[0,0]]])\n",
    "\n",
    "plot_confusion_matrix(cm, ['0', '1'], )\n",
    "acc, pr, tpr, fpr = show_data(cm, print_res = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hard to say which decision boundary is optimal. We want to minimize FPR, but accuracy is getting trashed at higher thresholds. Time to try other models: SVM, RF, GB...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()  #tried all kernels, SVC just doesn't do well here\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "if lrn.classes_[0] == 1:\n",
    "    cm = np.array([[cm[1,1], cm[1,0]], [cm[0,1], cm[0,0]]])\n",
    "\n",
    "plot_confusion_matrix(cm, ['0', '1'], )\n",
    "acc, pr, tpr, fpr = show_data(cm, print_res = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using unscaled data (seems to do slightly better than with scaled data):\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state=313)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    break\n",
    "\n",
    "accs = []\n",
    "prs = []\n",
    "tprs = []\n",
    "fprs = []\n",
    "for i in range(100):\n",
    "    rf = RandomForestClassifier() #\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    if lrn.classes_[0] == 1:\n",
    "        cm = np.array([[cm[1,1], cm[1,0]], [cm[0,1], cm[0,0]]])\n",
    "\n",
    "#     plot_confusion_matrix(cm, ['0', '1'], )\n",
    "    acc, pr, tpr, fpr = show_data(cm, print_res = 0)\n",
    "    \n",
    "    accs.append(acc)\n",
    "    prs.append(pr)\n",
    "    tprs.append(tpr)\n",
    "    fprs.append(fprs)\n",
    "    \n",
    "print(\"avg accuracy: \", np.mean(accs))\n",
    "print(\"avg precision: \", np.mean(prs))\n",
    "print(\"avg recall: \", np.mean(tprs))\n",
    "print(\"avg fallout: \", np.mean(fprs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using unscaled data (seems to make no difference scaled vs. unscaled):\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state=313)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "    break\n",
    "\n",
    "gb = GradientBoostingClassifier() #\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "if lrn.classes_[0] == 1:\n",
    "    cm = np.array([[cm[1,1], cm[1,0]], [cm[0,1], cm[0,0]]])\n",
    "\n",
    "plot_confusion_matrix(cm, ['0', '1'], )\n",
    "acc, pr, tpr, fpr = show_data(cm, print_res = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
